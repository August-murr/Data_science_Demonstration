{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/August-murr/Data_science_Demonstration/blob/main/Parallel%20Subtitle%20Collection%20and%20Alignment/Parallel_Subtitle_Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Subtitle Collection for Machine Translation\n",
        "\n",
        "Welcome to this Jupyter notebook, where our goal is to gather and prepare data for machine translation training or fine-tuning, focusing on movie subtitle translation.\n",
        "\n",
        "## Project Objective\n",
        "The primary objective of this notebook is to collect movie subtitle data from the popular website, Subscene.com. Subscene.com is renowned for its extensive collection of movie subtitles. We will leverage this resource to obtain subtitle files for various movies.\n",
        "\n",
        "## Data Preparation\n",
        "The core of our data preparation involves converting SRT (SubRip) subtitle files into two parallel subtitle files for a pair of languages. These parallel subtitle files are essential for training and evaluating machine translation models.\n",
        "\n",
        "Please note that while the code provided in this notebook accomplishes the task, there is room for further optimization and refinement in the future, which may be achieved through ongoing development or external contributions.\n",
        "\n",
        "Let's dive into the process of collecting, processing, and organizing subtitle data to support machine translation tasks.\n"
      ],
      "metadata": {
        "id": "RTAjMPdAMw8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and dependencies"
      ],
      "metadata": {
        "id": "oUEX5bmTPj33"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTd2HoGiLyHD"
      },
      "outputs": [],
      "source": [
        "# Install the langdetect library for language detection\n",
        "!pip install langdetect\n",
        "\n",
        "# Import the necessary libraries and modules\n",
        "import requests              # Used for making HTTP requests to websites\n",
        "from bs4 import BeautifulSoup  # Helps parse and extract data from HTML pages\n",
        "import os                    # Enables interaction with the file system\n",
        "from time import sleep       # Adds delays to prevent overloading web servers\n",
        "import shutil                # Provides file operations, useful for copying and moving files\n",
        "import zipfile               # Helps with handling zip files\n",
        "import pandas as pd          # Used for data manipulation and creating DataFrames\n",
        "import chardet              # Detects the encoding of text files\n",
        "from langdetect import detect  # Detects the language of text\n",
        "import langdetect           # Library for language detection\n",
        "import re                   # Allows working with regular expressions for text processing\n",
        "import langdetect.lang_detect_exception  # Exception handling for language detection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subtitle Zip File Download with web scraping"
      ],
      "metadata": {
        "id": "ZEWTn_8TPvmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `wait` function serves a crucial role in managing HTTP requests to the Subscene website. Subscene's HTTP request limits can behave in unpredictable ways, sometimes requiring longer waiting times between responses and at other times not needing any delay at all. To navigate these variations and avoid overloading the server, we introduce controlled pauses between requests."
      ],
      "metadata": {
        "id": "YLVGjdanQW74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wait(amount=2):\n",
        "  \"\"\"\n",
        "  This function is used to introduce delays in the code to avoid making too many requests in quick succession,\n",
        "  which can lead to server overload or rate limiting by websites.\n",
        "  The default duration is set to 2 seconds, but you can customize it by providing a different 'amount' in seconds.\n",
        "  \"\"\"\n",
        "  sleep(amount)"
      ],
      "metadata": {
        "id": "bnaKSrlTNVUp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the upcoming sections, we'll explore a set of functions designed to search for movie subtitles on Subscene.com based on the movie's title. The objective is to locate subtitles in different languages that share the same movie title. Subtitles with matching titles often have synchronized timestamps, simplifying the alignment process.\n",
        "\n",
        "However, it's important to note that these functions are optimized for movie subtitles and may not perform as effectively with TV series subtitles. TV series subtitle websites often follow different structural patterns, which may require separate handling."
      ],
      "metadata": {
        "id": "x8WOKJW0Sm29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tM3pFzmBUEcd"
      },
      "outputs": [],
      "source": [
        "def get_subscene_subtitle_link(movie_title):\n",
        "    # Define the URL and parameters for the search\n",
        "    url = \"https://subscene.com/subtitles/searchbytitle\"\n",
        "    params = {\"query\": movie_title}\n",
        "\n",
        "    # Define headers to prevent errors (you can customize this as needed)\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
        "    }\n",
        "    # Send a GET request to Subscene with the specified parameters and headers\n",
        "    response = requests.get(url, params=params, headers=headers)\n",
        "    wait()\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the first result's link\n",
        "        first_result = soup.find(\"div\", class_=\"title\")\n",
        "        if first_result:\n",
        "            link = first_result.find(\"a\")[\"href\"]\n",
        "            full_link = \"https://subscene.com\" + link\n",
        "            return full_link\n",
        "        else:\n",
        "            print(f\"No subtitle link found for '{movie_title}'.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the movie's subtitle link for '{movie_title}'. Status code:\", response.status_code)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2GNqWcocVOCI"
      },
      "outputs": [],
      "source": [
        "def get_subscene_subtitle_names(movie_name, language):\n",
        "    # Get the subtitle link for the movie\n",
        "    movie_link = get_subscene_subtitle_link(movie_name)\n",
        "\n",
        "    if movie_link:\n",
        "        # Construct the URL for the specific language's subtitle page\n",
        "        language_subtitle_url = f\"{movie_link}/{language}\"\n",
        "\n",
        "        # Define headers to prevent errors (you can customize this as needed)\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
        "        }\n",
        "        # Send a GET request to the language-specific subtitle page\n",
        "        response = requests.get(language_subtitle_url, headers=headers)\n",
        "        wait()\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Parse the HTML content of the page\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Find all subtitle entries\n",
        "            subtitle_entries = soup.find_all(\"td\", class_=\"a1\")\n",
        "\n",
        "            # Extract and return the names of positively rated subtitles\n",
        "            subtitle_names = []\n",
        "            for entry in subtitle_entries:\n",
        "                span_elements = entry.find_all(\"span\")\n",
        "                if len(span_elements) == 2 and \"positive-icon\" in span_elements[0].get(\"class\", []):\n",
        "                    subtitle_name = span_elements[1].text.strip()\n",
        "                    subtitle_names.append(subtitle_name)\n",
        "\n",
        "            return subtitle_names\n",
        "        else:\n",
        "            print(\"Failed to retrieve the language-specific subtitle page. Status code:\", response.status_code)\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"No results found for the movie title: {movie_name}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eCyGcqNLWc58"
      },
      "outputs": [],
      "source": [
        "def find_common_subtitles(list1, list2, priority=0):\n",
        "    # Convert the lists to sets to find the intersection\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "\n",
        "    # Find the common elements\n",
        "    common_elements = set1.intersection(set2)\n",
        "\n",
        "    # Convert the result back to a list\n",
        "    common_subtitles = list(common_elements)\n",
        "\n",
        "    if not common_subtitles:\n",
        "        print(\"No common subtitle names found.\")\n",
        "        return None\n",
        "\n",
        "    return common_subtitles[priority]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OJ2W9cy0ngUG"
      },
      "outputs": [],
      "source": [
        "def get_subtitle_href(movie_title, language, subtitle_name):\n",
        "    movie_page_link = get_subscene_subtitle_link(movie_title)\n",
        "    movie_page_link = movie_page_link + f\"/{language}\"\n",
        "\n",
        "    # Define headers to prevent errors (you can customize this as needed)\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
        "    }\n",
        "\n",
        "    # Send a GET request to the movie page\n",
        "    response = requests.get(movie_page_link, headers=headers)\n",
        "    wait()\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all subtitle entries\n",
        "        subtitle_entries = soup.find_all(\"a\", href=True)\n",
        "\n",
        "        # Search for the subtitle name and return the href for positively rated subtitles\n",
        "        for entry in subtitle_entries:\n",
        "            spans = entry.find_all(\"span\")\n",
        "            if len(spans) >= 2 and subtitle_name in spans[1].text:\n",
        "                if \"positive-icon\" in spans[0].get(\"class\"):\n",
        "                    href = entry[\"href\"]\n",
        "                    return f\"https://subscene.com{href}\"\n",
        "\n",
        "        print(f\"No positively rated subtitle '{subtitle_name}' found on the page.\")\n",
        "        return None\n",
        "    else:\n",
        "        print(\"Failed to retrieve the movie page. Status code:\", response.status_code)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below will create a folder with the same name as the movie in your desired directory and download the two zip files inside. It's important to note that this function requires two languages as input because it's designed to find subtitles that are synced between those two languages. If you're looking for subtitles in just one language, this code may not be suitable for your needs.\n"
      ],
      "metadata": {
        "id": "ZB9TYm80a6vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_download_link(subtitle_page_link):\n",
        "    # Define headers to prevent errors (you can customize this as needed)\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
        "    }\n",
        "    # Send a GET request to the subtitle page\n",
        "    response = requests.get(subtitle_page_link,headers=headers)\n",
        "    wait()\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the download link element\n",
        "        download_link = soup.find(\"a\", id=\"downloadButton\")\n",
        "\n",
        "        if download_link:\n",
        "            # Extract the href attribute and create the full download link\n",
        "            href = download_link.get(\"href\")\n",
        "            full_download_link = \"https://subscene.com\" + href\n",
        "            return full_download_link\n",
        "        else:\n",
        "            print(\"Download link not found on the page.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Failed to retrieve the subtitle page. Status code:\", response.status_code)\n",
        "        return None"
      ],
      "metadata": {
        "id": "EW4ess5KZNXQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nVO8Suafn8Ve"
      },
      "outputs": [],
      "source": [
        "# Function to create a folder if it doesn't exist\n",
        "def create_folder(folder_path):\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "# Function to download a file and save it with a specific name\n",
        "def download_file(url, destination):\n",
        "    # Define headers to prevent errors (you can customize this as needed)\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
        "    }\n",
        "    response = requests.get(url,headers=headers, stream=True)\n",
        "    wait()\n",
        "    with open(destination, 'wb') as out_file:\n",
        "        shutil.copyfileobj(response.raw, out_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VAafPmQfoV_B"
      },
      "outputs": [],
      "source": [
        "def download_subtitle_to(movie_title, language_1, language_2, save_to,priority=0):\n",
        "    # Get subtitle lists for both languages\n",
        "    language_1_list = get_subscene_subtitle_names(movie_title, language_1)\n",
        "    language_2_list = get_subscene_subtitle_names(movie_title, language_2)\n",
        "    # Find the common subtitle name\n",
        "    subtitle_name = find_common_subtitles(language_1_list, language_2_list,priority)\n",
        "\n",
        "    # Get subtitle page links\n",
        "    subtitle_page_link_1 = get_subtitle_href(movie_title, language_1, subtitle_name)\n",
        "    subtitle_page_link_2 = get_subtitle_href(movie_title, language_2, subtitle_name)\n",
        "\n",
        "    # Get download links\n",
        "    download_link_1 = get_download_link(subtitle_page_link_1)\n",
        "    download_link_2 = get_download_link(subtitle_page_link_2)\n",
        "\n",
        "    # Create the movie folder inside the \"save_to\" path\n",
        "    movie_folder = os.path.join(save_to, movie_title)\n",
        "    create_folder(movie_folder)\n",
        "\n",
        "    # Download subtitle files directly to the \"save_to\" path\n",
        "    download_file(download_link_1, os.path.join(movie_folder, f\"{movie_title}_{language_1}.zip\"))\n",
        "    download_file(download_link_2, os.path.join(movie_folder, f\"{movie_title}_{language_2}.zip\"))\n",
        "    return movie_folder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Alignment"
      ],
      "metadata": {
        "id": "1IhBQFxFbqsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a pair of zip files containing subtitles for a movie, our next steps are to unzip them and use the data to create dataframes.\n",
        "\n",
        "We have two types of dataframes: line_by_line and time_based.\n",
        "\n",
        "1. **Line-by-line dataframes:** In this method, each line of subtitle from one language is synced and paralleled with a line of subtitle from the other language. This approach is simpler and more convenient as each sentence is exactly matched with another. However, it can lead to information loss because not all lines in a subtitle file may find a parallel match.\n",
        "\n",
        "2. **Time-based dataframes:** Here, all the subtitles that happen within a minute of a movie are represented as a single row of data. This method is advantageous when dealing with languages that have very different structures and grammar. Not all languages can be translated sentence to sentence, and sometimes longer dependencies are required for better translation.\n",
        "\n",
        "Each method has its own set of advantages and disadvantages, and the choice between them depends on the specific characteristics of the subtitle content and the translation goals.\n"
      ],
      "metadata": {
        "id": "wllPrqUGdHLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ClwaxYAIpT7q"
      },
      "outputs": [],
      "source": [
        "def unzip_zipfile(zipfile_path):\n",
        "    try:\n",
        "        # Get the folder where the zip file is located\n",
        "        folder = os.path.dirname(zipfile_path)\n",
        "\n",
        "        # Create a list to store the paths of the extracted files\n",
        "        extracted_file_paths = []\n",
        "\n",
        "        # Open the zip file\n",
        "        with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:\n",
        "            # Extract all files in the zip to the same folder\n",
        "            zip_ref.extractall(folder)\n",
        "\n",
        "            # Get the names of the extracted files\n",
        "            extracted_files = zip_ref.namelist()\n",
        "\n",
        "            # Create paths for the extracted files\n",
        "            for extracted_file in extracted_files:\n",
        "                extracted_file_path = os.path.join(folder, extracted_file)\n",
        "                extracted_file_paths.append(extracted_file_path)\n",
        "\n",
        "        return extracted_file_paths\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bZJqxAXXpT5K"
      },
      "outputs": [],
      "source": [
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    clean_text = soup.get_text()\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RqhysnRjpZ2V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import chardet\n",
        "import pandas as pd\n",
        "\n",
        "def open_srt_as_dataframe(file_path):\n",
        "    try:\n",
        "        # Determine the file size to read a portion for encoding detection\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        bytes_to_read = min(1024, file_size)  # Read at most 1024 bytes for detection\n",
        "\n",
        "        # Read a portion of the file for encoding detection\n",
        "        with open(file_path, 'rb') as file:\n",
        "            raw_data = file.read(bytes_to_read)\n",
        "\n",
        "        # Detect the encoding\n",
        "        result = chardet.detect(raw_data)\n",
        "\n",
        "        # Get the detected encoding\n",
        "        detected_encoding = result['encoding']\n",
        "\n",
        "        # Open the file with the detected encoding\n",
        "        with open(file_path, 'r', encoding=detected_encoding, errors='replace') as file:\n",
        "            srt_content = file.read()\n",
        "\n",
        "        # Remove HTML tags from SRT content\n",
        "        clean_srt_content = remove_html_tags(srt_content)\n",
        "\n",
        "        # Split cleaned SRT content into individual subtitle blocks\n",
        "        subtitle_blocks = clean_srt_content.strip().split('\\n\\n')\n",
        "\n",
        "        # Parse the subtitle blocks into a DataFrame\n",
        "        data = {'number': [], 'start': [], 'end': [], 'content': []}\n",
        "        for block in subtitle_blocks:\n",
        "            lines = block.strip().split('\\n')\n",
        "            if len(lines) >= 3:\n",
        "                try:\n",
        "                    data['number'].append(int(lines[0]))\n",
        "                    start, end = lines[1].split(' --> ')\n",
        "                    data['start'].append(pd.to_datetime(start, format='%H:%M:%S,%f'))\n",
        "                    data['end'].append(pd.to_datetime(end, format='%H:%M:%S,%f'))\n",
        "                    data['content'].append('\\n'.join(lines[2:]))\n",
        "                except ValueError:\n",
        "                    continue  # Skip subtitle blocks that cannot be parsed\n",
        "            else:\n",
        "                continue  # Skip incomplete subtitle blocks\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After extensive testing of the functions with numerous movie subtitles, it became evident that, even with an encoder detected, many Arabic subtitles were not opened with the correct encoding. To address this issue, several new functions have been introduced, all of which are suffixed with \"_arabic.\" These functions are specifically designed for handling Arabic subtitles and should be used when downloading them.\n"
      ],
      "metadata": {
        "id": "QGnk9xP0h_dv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FKzpjQLdsKBe"
      },
      "outputs": [],
      "source": [
        "def open_srt_as_dataframe_arabic(file_path):\n",
        "    try:\n",
        "        # Determine the file size to read a portion for encoding detection\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        bytes_to_read = min(1024, file_size)  # Read at most 1024 bytes for detection\n",
        "\n",
        "        # Read a portion of the file for encoding detection\n",
        "        with open(file_path, 'rb') as file:\n",
        "            raw_data = file.read(bytes_to_read)\n",
        "\n",
        "        # Detect the encoding\n",
        "        result = chardet.detect(raw_data)\n",
        "\n",
        "        # Get the detected encoding\n",
        "        detected_encoding = result['encoding']\n",
        "\n",
        "        # Open the file with the detected encoding\n",
        "        with open(file_path, 'r', encoding=detected_encoding, errors='replace') as file:\n",
        "            srt_content = file.read()\n",
        "\n",
        "        # Detect the language of the first 30 lines using langdetect\n",
        "        try:\n",
        "            detected_language = detect(srt_content[:1000])\n",
        "        except langdetect.lang_detect_exception.LangDetectException:\n",
        "            detected_language = \"unknown\"\n",
        "\n",
        "        # If the detected language is Arabic, continue with Arabic content\n",
        "        if detected_language == \"ar\":\n",
        "            pass\n",
        "        else:\n",
        "            # Change the encoding to windows-1256 and read the file again\n",
        "            detected_encoding = \"windows-1256\"\n",
        "            with open(file_path, 'r', encoding=detected_encoding, errors='replace') as file:\n",
        "                srt_content = file.read()\n",
        "\n",
        "        # Remove HTML tags from SRT content\n",
        "        clean_srt_content = remove_html_tags(srt_content)\n",
        "\n",
        "        # Remove text within curly braces like {text}\n",
        "        clean_srt_content = re.sub(r'\\{.*?\\}', '', clean_srt_content)\n",
        "\n",
        "        # Split cleaned SRT content into individual subtitle blocks\n",
        "        subtitle_blocks = clean_srt_content.strip().split('\\n\\n')\n",
        "\n",
        "        # Parse the subtitle blocks into a DataFrame\n",
        "        data = {'number': [], 'start': [], 'end': [], 'content': []}\n",
        "        for block in subtitle_blocks:\n",
        "            lines = block.strip().split('\\n')\n",
        "            if len(lines) >= 3:\n",
        "                try:\n",
        "                    data['number'].append(int(lines[0]))\n",
        "                    start, end = lines[1].split(' --> ')\n",
        "                    data['start'].append(pd.to_datetime(start, format='%H:%M:%S,%f'))\n",
        "                    data['end'].append(pd.to_datetime(end, format='%H:%M:%S,%f'))\n",
        "                    data['content'].append('\\n'.join(lines[2:]))\n",
        "                except ValueError:\n",
        "                    continue  # Skip subtitle blocks that cannot be parsed\n",
        "            else:\n",
        "                continue  # Skip incomplete subtitle blocks\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pHY-03Zvtj07"
      },
      "outputs": [],
      "source": [
        "def remove_curly_braces(text):\n",
        "    return re.sub(r'\\{.*?\\}', '', text)\n",
        "\n",
        "def open_srt_as_dataframe_time_based(file_path):\n",
        "    try:\n",
        "        # Determine the file size to read a portion for encoding detection\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        bytes_to_read = min(1024, file_size)  # Read at most 1024 bytes for detection\n",
        "\n",
        "        # Read a portion of the file for encoding detection\n",
        "        with open(file_path, 'rb') as file:\n",
        "            raw_data = file.read(bytes_to_read)\n",
        "\n",
        "        # Detect the encoding\n",
        "        result = chardet.detect(raw_data)\n",
        "\n",
        "        # Get the detected encoding\n",
        "        detected_encoding = result['encoding']\n",
        "\n",
        "        # Open the file with the detected encoding\n",
        "        with open(file_path, 'r', encoding=detected_encoding, errors='replace') as file:\n",
        "            srt_content = file.read()\n",
        "\n",
        "        # Remove HTML tags from SRT content\n",
        "        clean_srt_content = remove_html_tags(srt_content)\n",
        "\n",
        "        # Split cleaned SRT content into individual subtitle blocks\n",
        "        subtitle_blocks = clean_srt_content.strip().split('\\n\\n')\n",
        "\n",
        "        # Initialize data for the DataFrame\n",
        "        data = {'hour': [], 'minute': [], 'content': []}\n",
        "\n",
        "        current_hour, current_minute = 0, 0\n",
        "        current_content = \"\"\n",
        "\n",
        "        for block in subtitle_blocks:\n",
        "            lines = block.strip().split('\\n')\n",
        "\n",
        "            if len(lines) >= 3:\n",
        "                # Extract the start time\n",
        "                start_time = pd.to_datetime(lines[1].split(' --> ')[0], format='%H:%M:%S,%f')\n",
        "                hour, minute = start_time.hour, start_time.minute\n",
        "\n",
        "                if hour != current_hour or minute != current_minute:\n",
        "                    if current_content:\n",
        "                        data['hour'].append(current_hour)\n",
        "                        data['minute'].append(current_minute)\n",
        "                        data['content'].append(current_content)\n",
        "\n",
        "                    current_hour, current_minute = hour, minute\n",
        "                    current_content = remove_curly_braces('\\n'.join(lines[2:]))\n",
        "                else:\n",
        "                    current_content += \"\\n\" + remove_curly_braces('\\n'.join(lines[2:]))\n",
        "\n",
        "        if current_content:\n",
        "            data['hour'].append(current_hour)\n",
        "            data['minute'].append(current_minute)\n",
        "            data['content'].append(current_content)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parallel_dataset(language_1_subtitles, language_2_subtitles, time_threshold=1):\n",
        "    # Merge the English and French subtitles using cross join\n",
        "    merged_df = pd.merge(language_1_subtitles, language_2_subtitles, how='cross')\n",
        "\n",
        "    # Calculate the time difference in seconds\n",
        "    merged_df[\"time_difference\"] = (merged_df[\"start_y\"] - merged_df[\"start_x\"]).dt.total_seconds()\n",
        "\n",
        "    # Filter the rows where the time difference is less than the threshold\n",
        "    parallel_df = merged_df[abs(merged_df[\"time_difference\"]) < time_threshold]\n",
        "\n",
        "    # Create a new dataframe with \"language_1\" and \"language_2\" columns\n",
        "    language_1_language_2 = parallel_df[[\"content_x\", \"content_y\"]]\n",
        "\n",
        "    # Rename the columns to \"language_1\" and \"language_2\"\n",
        "    language_1_language_2 = language_1_language_2.rename(columns={\"content_x\": \"language_1\", \"content_y\": \"language_2\"})\n",
        "\n",
        "    return language_1_language_2"
      ],
      "metadata": {
        "id": "ggr1vCmTxc2n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lz3uk9I0tm6O"
      },
      "outputs": [],
      "source": [
        "def create_parallel_dataset_time_based(df1, df2):\n",
        "    # Merge the 'content' columns from both DataFrames\n",
        "    merged_df = pd.merge(df1, df2, left_on=['hour', 'minute'], right_on=['hour', 'minute'], how='outer')\n",
        "\n",
        "    # Rename the 'content' columns from each DataFrame\n",
        "    merged_df.rename(columns={'content_x': 'language_1', 'content_y': 'language_2'}, inplace=True)\n",
        "\n",
        "    # Fill NaN values with empty strings\n",
        "    merged_df['language_1'].fillna('', inplace=True)\n",
        "    merged_df['language_2'].fillna('', inplace=True)\n",
        "\n",
        "    # Drop the 'hour' and 'minute' columns\n",
        "    merged_df.drop(['hour', 'minute'], axis=1, inplace=True)\n",
        "\n",
        "    return merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hj5KA1p3tvvQ"
      },
      "outputs": [],
      "source": [
        "def align_time_based(directory_path):\n",
        "    # List all zip files in the specified directory\n",
        "    zip_files = list_zip_files(directory_path)\n",
        "\n",
        "    # Sort the zip files to ensure the \"english.zip\" comes first\n",
        "    zip_files = sorted(zip_files, key=custom_sort_key)\n",
        "\n",
        "    # Extract and parse the first SRT file from the first zip file\n",
        "    zipfile_path = zip_files[0]\n",
        "    language_1_subtitles = open_srt_as_dataframe_time_based(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Extract and parse the second SRT file from the second zip file\n",
        "    zipfile_path = zip_files[1]\n",
        "    language_2_subtitles = open_srt_as_dataframe_time_based(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Create a parallel dataset with aligned subtitles\n",
        "    parallel_dataset = create_parallel_dataset_time_based(language_1_subtitles, language_2_subtitles)\n",
        "\n",
        "    # Reset the index and drop the extra index column\n",
        "    #parallel_dataset = parallel_dataset.reset_index().drop(\"index\", axis=1)\n",
        "\n",
        "    # Save the parallel dataset as a CSV in the same directory\n",
        "    csv_path = os.path.join(directory_path, \"parallel_subtitle_time_based.csv\")\n",
        "    parallel_dataset.to_csv(csv_path, index=False)\n",
        "\n",
        "    # Print a success message\n",
        "    print(\"Alignment and Time Based CSV creation completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_time_based_arabic(directory_path):\n",
        "    # List all zip files in the specified directory\n",
        "    zip_files = list_zip_files(directory_path)\n",
        "\n",
        "    # Sort the zip files to ensure the \"english.zip\" comes first\n",
        "    zip_files = sorted(zip_files, key=custom_sort_key)\n",
        "\n",
        "    # Extract and parse the first SRT file from the first zip file\n",
        "    zipfile_path = zip_files[0]\n",
        "    language_1_subtitles = open_srt_as_dataframe_time_based(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Extract and parse the second SRT file from the second zip file\n",
        "    zipfile_path = zip_files[1]\n",
        "    language_2_subtitles = open_srt_as_dataframe_time_based_arabic(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Create a parallel dataset with aligned subtitles\n",
        "    parallel_dataset = create_parallel_dataset_time_based(language_1_subtitles, language_2_subtitles)\n",
        "\n",
        "    # Reset the index and drop the extra index column\n",
        "\n",
        "    # Save the parallel dataset as a CSV in the same directory\n",
        "    csv_path = os.path.join(directory_path, \"parallel_subtitle_time_based.csv\")\n",
        "    parallel_dataset.to_csv(csv_path, index=False)\n",
        "\n",
        "    # Print a success message\n",
        "    print(\"Alignment and Time Based CSV creation completed successfully.\")"
      ],
      "metadata": {
        "id": "XswPV7LG2IQ0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CApl_TKps3a7"
      },
      "outputs": [],
      "source": [
        "def list_zip_files(directory):\n",
        "    zip_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".zip\"):\n",
        "                zip_files.append(os.path.join(root, file))\n",
        "\n",
        "    return zip_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TUOH90H7s8XO"
      },
      "outputs": [],
      "source": [
        "# Custom sorting key function\n",
        "def custom_sort_key(item):\n",
        "    if item.endswith(\"english.zip\"):\n",
        "        return (0, item)  # Assign a lower sort key for strings ending with \"english.zip\"\n",
        "    else:\n",
        "        return (1, item)  # Assign a higher sort key for other strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UeNJSQeEtAyV"
      },
      "outputs": [],
      "source": [
        "def open_srt_as_dataframe_time_based_arabic(file_path):\n",
        "    try:\n",
        "        # Determine the file size to read a portion for encoding detection\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        bytes_to_read = min(1024, file_size)  # Read at most 1024 bytes for detection\n",
        "\n",
        "        # Read a portion of the file for encoding detection\n",
        "        with open(file_path, 'rb') as file:\n",
        "            raw_data = file.read(bytes_to_read)\n",
        "\n",
        "        # Detect the encoding\n",
        "        result = chardet.detect(raw_data)\n",
        "\n",
        "        # Get the detected encoding\n",
        "        detected_encoding = result['encoding']\n",
        "\n",
        "        # Open the file with the detected encoding\n",
        "        with open(file_path, 'r', encoding=detected_encoding, errors='replace') as file:\n",
        "            srt_content = file.read()\n",
        "\n",
        "        # Detect the language of the first 1000 characters using langdetect\n",
        "        try:\n",
        "            detected_language = detect(srt_content[:1000])\n",
        "        except langdetect.lang_detect_exception.LangDetectException:\n",
        "            detected_language = \"unknown\"\n",
        "\n",
        "        # If the detected language is Arabic, continue with Arabic content\n",
        "        if detected_language == \"ar\":\n",
        "            pass\n",
        "        else:\n",
        "            # Change the encoding to windows-1256 and read the file again\n",
        "            detected_encoding = \"windows-1256\"\n",
        "            with open(file_path, 'r', encoding=detected_encoding, errors='replace') as file:\n",
        "                srt_content = file.read()\n",
        "\n",
        "        # Remove text within curly braces like {text}\n",
        "        srt_content = re.sub(r'\\{.*?\\}', '', srt_content)\n",
        "\n",
        "        # Remove HTML tags from SRT content\n",
        "        clean_srt_content = re.sub(r'<[^>]*>', '', srt_content)\n",
        "\n",
        "        # Split cleaned SRT content into individual subtitle blocks\n",
        "        subtitle_blocks = clean_srt_content.strip().split('\\n\\n')\n",
        "\n",
        "        # Initialize data for the DataFrame\n",
        "        data = {'hour': [], 'minute': [], 'content': []}\n",
        "\n",
        "        current_hour, current_minute = 0, 0\n",
        "        current_content = \"\"\n",
        "\n",
        "        for block in subtitle_blocks:\n",
        "            lines = block.strip().split('\\n')\n",
        "\n",
        "            if len(lines) >= 3:\n",
        "                # Extract the start time\n",
        "                start_time = pd.to_datetime(lines[1].split(' --> ')[0], format='%H:%M:%S,%f')\n",
        "                hour, minute = start_time.hour, start_time.minute\n",
        "\n",
        "                if hour != current_hour or minute != current_minute:\n",
        "                    if current_content:\n",
        "                        data['hour'].append(current_hour)\n",
        "                        data['minute'].append(current_minute)\n",
        "                        data['content'].append(current_content)\n",
        "\n",
        "                    current_hour, current_minute = hour, minute\n",
        "                    current_content = remove_curly_braces('\\n'.join(lines[2:]))\n",
        "                else:\n",
        "                    current_content += \"\\n\" + remove_curly_braces('\\n'.join(lines[2:]))\n",
        "\n",
        "        if current_content:\n",
        "            data['hour'].append(current_hour)\n",
        "            data['minute'].append(current_minute)\n",
        "            data['content'].append(current_content)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Z5a_aEQjuGdp"
      },
      "outputs": [],
      "source": [
        "def align(directory_path, time_threshold=1):\n",
        "    # List all zip files in the specified directory\n",
        "    zip_files = list_zip_files(directory_path)\n",
        "\n",
        "    # Sort the zip files to ensure the \"english.zip\" comes first\n",
        "    zip_files = sorted(zip_files, key=custom_sort_key)\n",
        "\n",
        "    # Extract and parse the first SRT file from the first zip file\n",
        "    zipfile_path = zip_files[0]\n",
        "    language_1_subtitles = open_srt_as_dataframe(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Extract and parse the second SRT file from the second zip file\n",
        "    zipfile_path = zip_files[1]\n",
        "    language_2_subtitles = open_srt_as_dataframe(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Create a parallel dataset with aligned subtitles\n",
        "    parallel_dataset = create_parallel_dataset(language_1_subtitles, language_2_subtitles, time_threshold)\n",
        "\n",
        "    # Reset the index and drop the extra index column\n",
        "    parallel_dataset = parallel_dataset.reset_index().drop(\"index\", axis=1)\n",
        "\n",
        "    # Save the parallel dataset as a CSV in the same directory\n",
        "    csv_path = os.path.join(directory_path, \"parallel_subtitle_line_by_line.csv\")\n",
        "    parallel_dataset.to_csv(csv_path, index=False)\n",
        "\n",
        "    # Print a success message\n",
        "    print(\"Alignment and CSV creation completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XmJGpfn-vleC"
      },
      "outputs": [],
      "source": [
        "def align_arabic(directory_path, time_threshold=1):\n",
        "    # List all zip files in the specified directory\n",
        "    zip_files = list_zip_files(directory_path)\n",
        "\n",
        "    # Sort the zip files to ensure the \"english.zip\" comes first\n",
        "    zip_files = sorted(zip_files, key=custom_sort_key)\n",
        "\n",
        "    # Extract and parse the first SRT file from the first zip file\n",
        "    zipfile_path = zip_files[0]\n",
        "    language_1_subtitles = open_srt_as_dataframe(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Extract and parse the second SRT file from the second zip file\n",
        "    zipfile_path = zip_files[1]\n",
        "    language_2_subtitles = open_srt_as_dataframe_arabic(unzip_zipfile(zipfile_path)[0])\n",
        "\n",
        "    # Create a parallel dataset with aligned subtitles\n",
        "    parallel_dataset = create_parallel_dataset(language_1_subtitles, language_2_subtitles, time_threshold)\n",
        "\n",
        "    # Reset the index and drop the extra index column\n",
        "    parallel_dataset = parallel_dataset.reset_index().drop(\"index\", axis=1)\n",
        "\n",
        "    # Save the parallel dataset as a CSV in the same directory\n",
        "    csv_path = os.path.join(directory_path, \"parallel_subtitle_line_by_line.csv\")\n",
        "    parallel_dataset.to_csv(csv_path, index=False)\n",
        "\n",
        "    # Print a success message\n",
        "    print(\"Alignment and CSV creation completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def has_csv_file(file_path):\n",
        "    # Check if the directory exists\n",
        "    if not os.path.exists(file_path):\n",
        "        return False\n",
        "\n",
        "    # List all files in the directory\n",
        "    files = os.listdir(file_path)\n",
        "\n",
        "    # Check if any file has a .csv extension\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "EWqPT6v5yYB0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_folder_and_contents(folder_path):\n",
        "    try:\n",
        "        # Check if the folder exists\n",
        "        if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
        "            print(\"Folder does not exist or is not a directory.\")\n",
        "            return\n",
        "\n",
        "        # Delete the entire folder and its contents\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Deleted folder and its contents: {folder_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "27DW74eFzJpf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_csv_in_folder(folder_path, filename=\"parallel_subtitle_line_by_line.csv\"):\n",
        "    try:\n",
        "        # Check if the folder exists\n",
        "        if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
        "            print(\"Folder does not exist or is not a directory.\")\n",
        "            return None\n",
        "\n",
        "        # Iterate through the files in the folder\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                if file == filename:\n",
        "                    # Found the CSV file with the specified name\n",
        "                    return os.path.join(root, file)\n",
        "\n",
        "        print(f\"CSV file '{filename}' not found in the folder.\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "lTpuwL-810Br"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Furthermore, an additional function has been implemented to automatically detect the languages of the downloaded subtitle files. This serves the purpose of ensuring that the language pair is consistent and that the subtitle files are not corrupted. It adds an extra layer of verification to the subtitle acquisition process.\n"
      ],
      "metadata": {
        "id": "JhdH8fGdidWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_language_from_csv_column(csv_path, column_name):\n",
        "    try:\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Extract the first 20 rows from the specified column\n",
        "        first_20_rows = df[column_name].head(20).str.cat()\n",
        "\n",
        "        # Detect the language of the concatenated string\n",
        "        detected_language = detect(first_20_rows)\n",
        "\n",
        "        return detected_language\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return None"
      ],
      "metadata": {
        "id": "GUeIaEHV13SK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_non_zip_csv_files(folder_path):\n",
        "    try:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for filename in files:\n",
        "                file_path = os.path.join(root, filename)\n",
        "                if not (filename.endswith(\".zip\") or filename.endswith(\".csv\")):\n",
        "                    os.remove(file_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return False"
      ],
      "metadata": {
        "id": "P4ftLKcWkNUi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final function, while it may appear somewhat intricate and includes some repetition, is designed to achieve a specific set of tasks. It begins by creating a folder named after the movie and downloading two subtitle zip files into it. Subsequently, the align function attempts to generate a parallel subtitle file. If this process encounters an error, the zip files are replaced with another pair, and the align function is re-executed. This retry mechanism is repeated up to three times to ensure successful alignment. Once all operations are completed successfully, a language detector is used to print the detected languages of the downloaded subtitle files for verification. Finally, the function cleans the folder by removing unnecessary files to maintain a tidy workspace.\n"
      ],
      "metadata": {
        "id": "VM4EfNdsi7Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parallel_subtitles_line_by_line(movie_title,language_1,language_2,save_to,time_threshold=0.7):\n",
        "  dir = download_subtitle_to(movie_title,language_1,language_2,save_to)\n",
        "  try:\n",
        "    align(dir,time_threshold)\n",
        "  except:\n",
        "    pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=1)\n",
        "    try:\n",
        "      align(dir, time_threshold)\n",
        "    except:\n",
        "      pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=2)\n",
        "    try:\n",
        "      align(dir, time_threshold)\n",
        "    except:\n",
        "      pass\n",
        "  csv_path = find_csv_in_folder(dir)\n",
        "  first_lan = detect_language_from_csv_column(csv_path,\"language_1\")\n",
        "  second_lan = detect_language_from_csv_column(csv_path,\"language_2\")\n",
        "  print(f\"language pair of {os.path.basename(dir) } is {first_lan}:{second_lan}\")\n",
        "  delete_non_zip_csv_files(dir)"
      ],
      "metadata": {
        "id": "2nsQOo1I3rc_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parallel_subtitles_time_based(movie_title,language_1,language_2,save_to,time_threshold=0.7):\n",
        "  dir = download_subtitle_to(movie_title,language_1,language_2,save_to)\n",
        "  try:\n",
        "    align_time_based(dir)\n",
        "  except:\n",
        "    pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=1)\n",
        "    try:\n",
        "      align_time_based(dir)\n",
        "    except:\n",
        "      pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=2)\n",
        "    try:\n",
        "      align_time_based(dir)\n",
        "    except:\n",
        "      pass\n",
        "  csv_path = find_csv_in_folder(dir)\n",
        "  first_lan = detect_language_from_csv_column(csv_path,\"language_1\")\n",
        "  second_lan = detect_language_from_csv_column(csv_path,\"language_2\")\n",
        "  print(f\"language pair of {os.path.basename(dir) } is {first_lan}:{second_lan}\")\n",
        "  delete_non_zip_csv_files(dir)"
      ],
      "metadata": {
        "id": "-gFAshDc8TNR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parallel_subtitles_arabic_line_by_line(movie_title,language_1,language_2,save_to,time_threshold=0.7):\n",
        "  dir = download_subtitle_to(movie_title,language_1,language_2,save_to)\n",
        "  try:\n",
        "    align_arabic(dir,time_threshold)\n",
        "  except:\n",
        "    pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=1)\n",
        "    try:\n",
        "      align_arabic(dir, time_threshold)\n",
        "    except:\n",
        "      pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=2)\n",
        "    try:\n",
        "      align_arabic(dir, time_threshold)\n",
        "    except:\n",
        "      pass\n",
        "  csv_path = find_csv_in_folder(dir)\n",
        "  first_lan = detect_language_from_csv_column(csv_path,\"language_1\")\n",
        "  second_lan = detect_language_from_csv_column(csv_path,\"language_2\")\n",
        "  print(f\"language pair of {os.path.basename(dir) } is {first_lan}:{second_lan}\")\n",
        "  delete_non_zip_csv_files(dir)"
      ],
      "metadata": {
        "id": "5n5_5bgc9-Md"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parallel_subtitles_arabic_time_based(movie_title,language_1,language_2,save_to,time_threshold=0.7):\n",
        "  dir = download_subtitle_to(movie_title,language_1,language_2,save_to)\n",
        "  try:\n",
        "    align_time_based_arabic(dir)\n",
        "  except:\n",
        "    pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=1)\n",
        "    try:\n",
        "      align_time_based_arabic(dir)\n",
        "    except:\n",
        "      pass\n",
        "  if has_csv_file(dir)==False:\n",
        "    delete_folder_and_contents(dir)\n",
        "    dir = download_subtitle_to(movie_title,language_1,language_2,save_to,priority=2)\n",
        "    try:\n",
        "      align_time_based_arabic(dir)\n",
        "    except:\n",
        "      pass\n",
        "  csv_path = find_csv_in_folder(dir)\n",
        "  first_lan = detect_language_from_csv_column(csv_path,\"language_1\")\n",
        "  second_lan = detect_language_from_csv_column(csv_path,\"language_2\")\n",
        "  print(f\"language pair of {os.path.basename(dir) } is {first_lan}:{second_lan}\")\n",
        "  delete_non_zip_csv_files(dir)"
      ],
      "metadata": {
        "id": "u2rIhDfT8YnL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "XffervnokQSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie = \"Blade Runner 2049\"\n",
        "language_1 = \"english\"\n",
        "language_2 = \"french\"\n",
        "save_to = \"/content\"#path to save the downloaded subtitles"
      ],
      "metadata": {
        "id": "AIhdAfn03jnz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_parallel_subtitles_line_by_line(movie, language_1, language_2, save_to)\n",
        "create_parallel_subtitles_time_based(movie, language_1, language_2, save_to)"
      ],
      "metadata": {
        "id": "2TA7DQenewj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ea4ec0-eb91-4c8f-9084-a4d29a0b7029"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alignment and CSV creation completed successfully.\n",
            "language pair of Blade Runner 2049 is en:fr\n",
            "Alignment and Time Based CSV creation completed successfully.\n",
            "language pair of Blade Runner 2049 is en:fr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've also uploaded the parallel subtitle files to my google drive which can be downloaded with gdown."
      ],
      "metadata": {
        "id": "ByaUWrFUPWGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "id": "aCBfoUC3L7uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown"
      ],
      "metadata": {
        "id": "2aIJRuRhL_JO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file ID and the output filename\n",
        "file_id = \"1Iw0TonQcDTAfJfzElasg6pt92322zem6\"\n",
        "output_filename = \"Blade_Runner_2049_line_by_line.csv\"\n",
        "\n",
        "# Download the file from Google Drive\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_filename, quiet=False)"
      ],
      "metadata": {
        "id": "h1JXTLvLMFKX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "510955ec-9681-4156-c3af-463ae0910eef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Iw0TonQcDTAfJfzElasg6pt92322zem6\n",
            "To: /content/Blade_Runner_2049_line_by_line.csv\n",
            "100%|██████████| 61.4k/61.4k [00:00<00:00, 57.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Blade_Runner_2049_line_by_line.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file ID and the output filename\n",
        "file_id = \"16zSr8T7TOMg4wkc6-3rLdTYbqr7bG06j\"\n",
        "output_filename = \"Blade_Runner_2049_time_based.csv\"\n",
        "\n",
        "# Download the file from Google Drive\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_filename, quiet=False)"
      ],
      "metadata": {
        "id": "gxFTZ9IANX9r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8d15a927-e048-4fdf-d752-01e750aa57fb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16zSr8T7TOMg4wkc6-3rLdTYbqr7bG06j\n",
            "To: /content/Blade_Runner_2049_time_based.csv\n",
            "100%|██████████| 70.9k/70.9k [00:00<00:00, 73.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Blade_Runner_2049_time_based.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line_by_line = pd.read_csv(\"/content/Blade_Runner_2049_line_by_line.csv\")\n",
        "time_based = pd.read_csv(\"/content/Blade_Runner_2049_time_based.csv\")"
      ],
      "metadata": {
        "id": "dJciUBPsNyUC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_by_line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QKYsNNANN1Kz",
        "outputId": "13aca554-57a1-45a6-bb12-7b20e616270e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           language_1  \\\n",
              "0    K: I hope you don't mind me\\ntaking the liberty.   \n",
              "1             I was careful\\nnot to drag in any dirt.   \n",
              "2                      SAPPER: I don't mind the dirt.   \n",
              "3                                           I do mind   \n",
              "4                                 unannounced visits.   \n",
              "..                                                ...   \n",
              "950                                  Who am I to you?   \n",
              "951                            Go meet your daughter.   \n",
              "952                                         You okay?   \n",
              "953                                    Just a moment.   \n",
              "954                              Beautiful, isn't it?   \n",
              "\n",
              "                                            language_2  \n",
              "0    Je me suis permis, Ca ne vous dérange pas,\\nj’...  \n",
              "1    J’ai fait attention à ne pas laisser\\nentrer d...  \n",
              "2                         Je me fiche de la poussière.  \n",
              "3                                      Mais pas pareil  \n",
              "4                           …pour visites inattendues.  \n",
              "..                                                 ...  \n",
              "950                    Qu'est ce que je suis pour toi?  \n",
              "951                                  Va voir ta fille.  \n",
              "952                                       Ca va aller?  \n",
              "953                        Un instant s'il vous plait?  \n",
              "954                    C'est magnifique, n'est-ce pas?  \n",
              "\n",
              "[955 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cad18a0-a64a-40f4-a436-9c5f084be9b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language_1</th>\n",
              "      <th>language_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>K: I hope you don't mind me\\ntaking the liberty.</td>\n",
              "      <td>Je me suis permis, Ca ne vous dérange pas,\\nj’...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I was careful\\nnot to drag in any dirt.</td>\n",
              "      <td>J’ai fait attention à ne pas laisser\\nentrer d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SAPPER: I don't mind the dirt.</td>\n",
              "      <td>Je me fiche de la poussière.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I do mind</td>\n",
              "      <td>Mais pas pareil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unannounced visits.</td>\n",
              "      <td>…pour visites inattendues.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>950</th>\n",
              "      <td>Who am I to you?</td>\n",
              "      <td>Qu'est ce que je suis pour toi?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>Go meet your daughter.</td>\n",
              "      <td>Va voir ta fille.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>952</th>\n",
              "      <td>You okay?</td>\n",
              "      <td>Ca va aller?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>Just a moment.</td>\n",
              "      <td>Un instant s'il vous plait?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>Beautiful, isn't it?</td>\n",
              "      <td>C'est magnifique, n'est-ce pas?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>955 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cad18a0-a64a-40f4-a436-9c5f084be9b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cad18a0-a64a-40f4-a436-9c5f084be9b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cad18a0-a64a-40f4-a436-9c5f084be9b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ec63c00-00a1-46cd-ac4e-0db32ca0ef20\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ec63c00-00a1-46cd-ac4e-0db32ca0ef20')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ec63c00-00a1-46cd-ac4e-0db32ca0ef20 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_based"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lTO1xFfrN_-M",
        "outputId": "0bae4ea3-e9cb-4d13-f4f9-590ebe2529ca"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            language_1  \\\n",
              "0                        \\nSubtitles by explosiveskull   \n",
              "1                    (ALARM BUZZES)\\n(BREATHES DEEPLY)   \n",
              "2                               (AIRCRAFT APPROACHING)   \n",
              "3    (SPRAY HISSING)\\n(HISSING STOPS)\\n(DRONE HOVER...   \n",
              "4    (POT BOILING)\\n(TAP RUNNING)\\n(TAP STOPS)\\nK: ...   \n",
              "..                                                 ...   \n",
              "141  You shoulda let me\\ndie out there.\\nK: You did...   \n",
              "142  All the best memories\\nare hers.\\nWhy?\\nWho am...   \n",
              "143  Just a moment.\\nBeautiful, isn't it?\\nSubtitle...   \n",
              "144                                                NaN   \n",
              "145                                                NaN   \n",
              "\n",
              "                                            language_2  \n",
              "0    \\nPh3nIc3\\nEnjoy and Merry Christmas !!! Joyeu...  \n",
              "1                                                  NaN  \n",
              "2                                                  NaN  \n",
              "3                                                  NaN  \n",
              "4    Je me suis permis, Ca ne vous dérange pas,\\nj’...  \n",
              "..                                                 ...  \n",
              "141  Tu aurais du me laisser mourir là dedans.\\nC'e...  \n",
              "142  Tous les meilleurs souvenirs sont les siens.\\n...  \n",
              "143  Un instant s'il vous plait?\\nC'est magnifique,...  \n",
              "144  L'effondrement de l'Ecosystème au milieu des a...  \n",
              "145             <<< Ph3nIc3 >>>\\nTraduction 2017.12.27  \n",
              "\n",
              "[146 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02d6818d-7510-4fd4-a58f-e27c5a0748e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language_1</th>\n",
              "      <th>language_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\nSubtitles by explosiveskull</td>\n",
              "      <td>\\nPh3nIc3\\nEnjoy and Merry Christmas !!! Joyeu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(ALARM BUZZES)\\n(BREATHES DEEPLY)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(AIRCRAFT APPROACHING)</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(SPRAY HISSING)\\n(HISSING STOPS)\\n(DRONE HOVER...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(POT BOILING)\\n(TAP RUNNING)\\n(TAP STOPS)\\nK: ...</td>\n",
              "      <td>Je me suis permis, Ca ne vous dérange pas,\\nj’...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>You shoulda let me\\ndie out there.\\nK: You did...</td>\n",
              "      <td>Tu aurais du me laisser mourir là dedans.\\nC'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>All the best memories\\nare hers.\\nWhy?\\nWho am...</td>\n",
              "      <td>Tous les meilleurs souvenirs sont les siens.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>Just a moment.\\nBeautiful, isn't it?\\nSubtitle...</td>\n",
              "      <td>Un instant s'il vous plait?\\nC'est magnifique,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>NaN</td>\n",
              "      <td>L'effondrement de l'Ecosystème au milieu des a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;&lt;&lt; Ph3nIc3 &gt;&gt;&gt;\\nTraduction 2017.12.27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02d6818d-7510-4fd4-a58f-e27c5a0748e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02d6818d-7510-4fd4-a58f-e27c5a0748e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02d6818d-7510-4fd4-a58f-e27c5a0748e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb57aa8f-ad29-4c38-9207-dea1d53ee91c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb57aa8f-ad29-4c38-9207-dea1d53ee91c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb57aa8f-ad29-4c38-9207-dea1d53ee91c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}